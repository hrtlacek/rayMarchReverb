% Template LaTeX file for DAFx-20 papers
%
% To generate the correct references using BibTeX, run
%     latex, bibtex, latex, latex
% modified...
% - from DAFx-00 to DAFx-02 by Florian Keiler, 2002-07-08
% - from DAFx-03 to DAFx-04 by Gianpaolo Evangelista, 2004-02-07 
% - from DAFx-05 to DAFx-06 by Vincent Verfaille, 2006-02-05
% - from DAFx-06 to DAFx-07 by Vincent Verfaille, 2007-01-05
%                          and Sylvain Marchand, 2007-01-31
% - from DAFx-07 to DAFx-08 by Henri Penttinen, 2007-12-12
%                          and Jyri Pakarinen 2008-01-28
% - from DAFx-08 to DAFx-09 by Giorgio Prandi, Fabio Antonacci 2008-10-03
% - from DAFx-09 to DAFx-10 by Hannes Pomberger 2010-02-01
% - from DAFx-10 to DAFx-12 by Jez Wells 2011
% - from DAFx-12 to DAFx-14 by Sascha Disch 2013
% - from DAFx-15 to DAFx-16 by Pavel Rajmic 2015
% - from DAFx-16 to DAFx-17 by Brian Hamilton 2016
% - from DAFx-17 to DAFx-18 by Annibal Ferreira and Matthew Davies 2017
% - from DAFx-18 to DAFx-19 by Dave Moffat 2019
% - from DAFx-19 to DAFx-20 by Gianpaolo Evangelista 2019
%
% Template with hyper-references (links) active after conversion to pdf
% (with the distiller) or if compiled with pdflatex.
%
% 20060205: added package 'hypcap' to correct hyperlinks to figures and tables
%                      use of \papertitle and \paperauthorA, etc for same title in PDF and Metadata
% 20190205: Package 'hypcap' removed, and replaced with 'caption', to allow for the inclusion
%			of a CC UP licence.
%
% 1) Please compile using latex or pdflatex.
% 2) If using pdflatex, you need your figures in a file format other than eps! e.g. png or jpg is working
% 3) Please use "paperftitle" and "pdfauthor" definitions below

%------------------------------------------------------------------------------------------
%  !  !  !  !  !  !  !  !  !  !  !  ! user defined variables  !  !  !  !  !  !  !  !  !  !  !  !  !  !
% Please use the following commands to define title and author(s) of the paper.
% paperauthorA MUST be the the first author of the paper
% Please comment the unused definitions 
\def\papertitle{Room Impulse Response Estimation using Signed Distance Functons}
\def\paperauthorA{Patrik Lechner}
\def\paperauthorB{Author Two}
\def\paperauthorC{Author Three}
\def\paperauthorD{Author Four}
%\def\paperauthorE{Author Five}
%\def\paperauthorF{Author Six}
%\def\paperauthorG{Author Seven}
%\def\paperauthorH{Author Eight}
%\def\paperauthorI{Author Nine}
%\def\paperauthorJ{Author Ten}

% Authors' affiliations have to be set below

%------------------------------------------------------------------------------------------
\documentclass[twoside,a4paper]{article}
\usepackage{etoolbox}
\usepackage{dafx_20}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{euscript}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{lmodern}
\usepackage{nimbusserif}
\usepackage{ifpdf}
\usepackage[english]{babel}
\usepackage{caption}
% \usepackage{subfig} % or can use subcaption package
\usepackage{color}

\input glyphtounicode
\pdfgentounicode=1

\setcounter{page}{1}
\ninept

% build the list of authors and set the flag \multipleauth to handle the et al. in the copyright note (in DAFx_20.sty)
%==============================DO NOT MODIFY =======================================
\newcounter{numauth}\setcounter{numauth}{1}
\newcounter{listcnt}\setcounter{listcnt}{1}
\newcommand\authcnt[1]{\ifdefined#1 \stepcounter{numauth} \fi}

\newcommand\addauth[1]{
\ifdefined#1 
\stepcounter{listcnt}
\ifnum \value{listcnt}<\value{numauth}
\appto\authorslist{, #1}
\else
\appto\authorslist{~and~#1}
\fi
\fi}
%======DO NOT MODIFY UNLESS YOUR PAPER HAS MORE THAN 10 AUTHORS========================
%==we count the authors defined at the beginning of the file (paperauthorA is mandatory and already accounted for)
\authcnt{\paperauthorB}
\authcnt{\paperauthorC}
\authcnt{\paperauthorD}
\authcnt{\paperauthorE}
\authcnt{\paperauthorF}
\authcnt{\paperauthorG}
\authcnt{\paperauthorH}
\authcnt{\paperauthorI}
\authcnt{\paperauthorJ}
%==we create a list of authors for pdf tagging, for example: paperauthorA, paperauthorB, ... and paperauthorF (last author)
\def\authorslist{\paperauthorA}
\addauth{\paperauthorB}
\addauth{\paperauthorC}
\addauth{\paperauthorD}
\addauth{\paperauthorE}
\addauth{\paperauthorF}
\addauth{\paperauthorG}
\addauth{\paperauthorH}
\addauth{\paperauthorI}
\addauth{\paperauthorJ}
%====================================================================================

\usepackage{times}
% Saves a lot of ouptut space in PDF... after conversion with the distiller
% Delete if you cannot get PS fonts working on your system.


% pdf-tex settings: detect automatically if run by latex or pdflatex
\newif\ifpdf
\ifx\pdfoutput\relax
\else
   \ifcase\pdfoutput
      \pdffalse
   \else
      \pdftrue
\fi

\ifpdf % compiling with pdflatex
  \usepackage[pdftex,
    pdftitle={\papertitle},
    pdfauthor={\authorslist},
    pdfsubject={Proceedings of the 23rd International Conference on Digital Audio Effects (DAFx-20)},
    colorlinks=false, % links are activated as color boxes instead of color text
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen; especially useful if working with a big screen :-)
  ]{hyperref}
  \pdfcompresslevel=9
  \usepackage[pdftex]{graphicx}
 % \usepackage[figure,table]{hypcap}
\else % compiling with latex
  \usepackage[dvips]{epsfig,graphicx}
  \usepackage[dvips,
    pdftitle={\papertitle},
    pdfauthor={\authorslist},
    pdfsubject={Proceedings of the 23rd International Conference on Digital Audio Effects (DAFx-20)},
    colorlinks=false, % no color links
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen
  ]{hyperref}
  % hyperrefs are active in the pdf file after conversion
  %\usepackage[figure,table]{hypcap}
\fi
\usepackage[hypcap=true]{caption}
\title{\papertitle}

% -------------SINGLE-AFFILIATION SINGLE-AUTHOR HEADER STARTS (uncomment below if your paper has a single author)----------------------------------------
\affiliation{
\paperauthorA\,\sthanks{Thanks to the predecessors for the templates}}
{\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Applied Sciences St.Poelten\\ St.Poelten, Austria\\
{\tt \href{mailto:dafx2020@gmail.com}{ptrk.lechner@gmail.com}}
}
%-------------SINGLE-AFFILIATION SINGLE-AUTHOR HEADER ENDS-------------------------------------------------------------------------------------------------------------------

%------------SINGLE-AFFILIATION MULTIPLE-AUTHORS HEADER STARTS (uncomment below if your paper has two or more authors from the same institution)
% \affiliation{
% \paperauthorA\,\sthanks{Thanks to the predecessors for the templates}and \paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
% {\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
% {\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
% }
%-----------------------------------SINGLE-AFFILIATION-MULTIPLE-AUTHORS HEADER ENDS----------------------------------------------------------------------------------------

%---------------TWO-AFFILIATIONS HEADER STARTS (uncomment below if your paper has two authors, each from a different institution)-----------------------------
%\twoaffiliations{
%\paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
%{\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
%{\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
%}
%{\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
%{\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
%}
%-------------------------------------TWO-AFFILIATIONS HEADER ENDS------------------------------------------------------

%%---------------THREE-AFFILIATIONS HEADER STARTS (uncomment below if your paper has three authors, each from a different institution)-----------------------
%\threeaffiliations{
%\paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
%{\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
%{\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
%}
%{\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
%{\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
%}
%{\paperauthorC \,\sthanks{Illustrious contributor}}
%{\href{http://dafx2018.web.ua.pt/}{IEETA} \\ University of Aveiro \\ Aveiro, Portugal \\ {\tt \href{mailto:dafx2018_papers@ua.pt}{dafx2018\_papers@ua.pt}}
%}
%-------------------------------------THREE-AFFILIATIONS HEADER ENDS------------------------------------------------------

%----------------FOUR-AFFILIATIONS HEADER STARTS (uncomment below if your paper has four authors, , each from a different institution)-----------------------
% \fouraffiliations{
% \paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
% {\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
% {\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
% }
% {\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
% {\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
% }
% {\paperauthorC \,\sthanks{Illustrious contributor}}
% {\href{http://dafx2018.web.ua.pt/}{IEETA} \\ University of Aveiro \\ Aveiro, Portugal \\ {\tt \href{mailto:dafx2018_papers@ua.pt}{dafx2018\_papers@ua.pt}}
% }
% {\paperauthorD \,\sthanks{This guy is a very good fellow}}
% {\href{http://www.acoustics.ed.ac.uk}{Acoustics and Audio Group} \\ University of Edinburgh\\ Edinburgh, UK\\ {\tt \href{mailto:dafx17@ed.ac.uk}{dafx17@ed.ac.uk}}
% }
%-------------------------------------FOUR-AFFILIATIONS HEADER ENDS------------------------------------------------------



% ============MY ADDITIONS ====================


\usepackage{pgf}
% -----------plotting with tikz-------
\usepackage{tikz}
\usepackage[utf8]{inputenc}
% \usepackage{fontspec}  % optional
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{dateplot}

% \usepgfplotslibrary{external} 
% \tikzexternalize
% ------------------------------------

% code
\usepackage{listings}
\lstset
{
frame = single,
}
% \lstset
% { %Formatting for code in appendix
%     % language=Matlab,
%     % basicstyle=\footnotesize,
%     numbers=left,
%     stepnumber=1,
%     showstringspaces=false,
%     tabsize=1,
%     breaklines=true,
%     breakatwhitespace=false,
% }

% subfigures (side by side)
\usepackage{subcaption}
% \usepackage{subfig}




% =============== BlockDiagram Drawing Config
\usetikzlibrary{shapes,arrows}
  \usetikzlibrary{trees, backgrounds}

% Definition of blocks:
\tikzset{%
  block/.style    = {draw, thick, rectangle, minimum height = 3em,
    minimum width = 3em},
  sum/.style      = {draw, circle, node distance = 2cm}, % Adder
  input/.style    = {coordinate}, % Input
  output/.style   = {coordinate}, % Output
  mult/.style   = {draw, isosceles triangle, minimum height=1cm, minimum width =1cm}
}
% mult/.style   = {isosceles triangle, sharp corners, anchor=center, xshift=-4mm, minimum height=1.5cm, minimum width =0.05cm}
%isosceles triangle, fill=gray!25, minimum width=1.5cm

% Defining string as labels of certain blocks.
\newcommand{\suma}{\Large$+$}
\newcommand{\inte}{$\displaystyle \int$}
\newcommand{\derv}{\huge$\frac{d}{dt}$}
\newcommand{\conv}{\huge$\ast$}

% ==

% ====================================






\begin{document}
% more pdf-tex settings:
\ifpdf % used graphic file format for pdflatex
  \DeclareGraphicsExtensions{.png,.jpg,.pdf}
\else  % used graphic file format for latex
  \DeclareGraphicsExtensions{.eps}
\fi

%\makeatletter
%\pdfbookmark[0]{\@pdftitle}{title}
%\makeatother

\maketitle

\begin{abstract}

Several algorithms and approaches for Room Impulse Response (RIR) estimation exist. To the best of the authors knowledge, there is no documentation of accuracy, speed or even the feasibility of using signed distance functions (SDFs) in combination with sphere tracing for this task. Here, a proof of concept with a focus on real-time performance is presented, that lacks many features such as frequency dependent absorption and scattering coefficients, arbitrary source and receiver directives etc. The results are shown and compared to real room impulse responses recorded by \cite{brinkmann_round_2019} and to a different simulation algorithm \cite{lehmann_fast_2020}. The implementation happens mostly inside a compute shader, an example application is provided in the framework \texttt{TouchDesigner}.\ 

The application as well as all generated data and \texttt{Jupyter Notebooks} can be found on this project's github repository\

 \href{https://github.com/hrtlacek/rayMarchReverb}{github.com/hrtlacek/rayMarchReverb}.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Sphere tracing as defined by \cite{hart_sphere_1996} is used extensively in the so called "demo scene" to render 3D video demos via shaders in real time for decades. 
Sphere tracing is a version of the ray casting algorithm \cite{roth_ray_1982}. It relies on the geometry being defined as so called signed distance functions (SDFs), and does not directly support the import of standard 3D Polygonal geometry or meshes. One of the advantages lies in the algorithm's potential improved speed in comparison to fixed-step ray casting. SDFs are used to describe implicit surfaces, typically via a function $f : \mathbb{R}^3 \rightarrow \mathbb{R}$(although in principle, arbitrary dimensions are possible, $f : \mathbb{R}^n \rightarrow \mathbb{R}$, see Section \ref{sec:concl}). This function should be designed to return a negative value if the locus of the point is inside the geometry, a positive value if outside and 0 if on the surface to define the desired geometry. Additionally it is advantageous to design this function in a way so it is lipschitz continuous. If $f$ is defined carefully, the distance to the nearest surface is returned by this function and therefore always known during stepping along a view-ray. 
Since the distance to the nearest surface is always known, the step size of a ray tracing algorithm can be dynamically adjusted, see Figure \ref{sphereViz}, resulting in fewer iterations along a ray, and therefore in significant speedups. 

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.5]{img/sphereTracingViz.png}}
\caption{\label{sphereViz}{\it Visualization of the sphere tracing algorithm in 2D. A ray is sent from the source (left) to the right until it hits a surface, always moving the maximum distance as the SDF informs the tracing algorithm about the distance to nearest surface.}}
\end{figure}

\subsection{Previous Work}
\label{ssec:prev}
A lot of previous work exists both in the field of Ray/sphere tracing and RIR estimation.
As shown in \cite{alpkocak_computing_2010} and \cite{brinkmann_round_2019} there are numerous approaches for estimating RIRs. Besides Ray-based methods such as the "Image Source Method", Ray-tracing and hybrid approaches, wave-based methods such as Finite Differences are becoming increasingly interesting due to advancements in computation power and research. Still, wave-based methods seem to be too slow for real-time applications. With the Pascal Architecture, NVIDIA introduced real-time ray tracing done on the GPU with NVIDIA VRWorks™ Audio \cite{noauthor_vrworks_nodate}.

% NVIDIA is working in the field of real time ray traced audio simulation
% NVIDIA VRWorks™ Audio (introduced with the Pascal GPU architecture) 



% \subsubsection*{RIR Estimation}
% \cite{alpkocak_computing_2010} gives an overview of methods in use for RIR estimation.


\subsubsection*{Sphere Tracing}
Sphere tracing itself was first described by \cite{hart_sphere_1996}. Many authors since then described improvements in speed e.g. \cite{balint_accelerating_2018} or the addition of features such as \cite{quilez_inigo_nodate}, \cite{keinert_enhanced_2014} or the activity of the \href{www.shadertoy.com}{shadertoy.com}-community.
Defining SDFs is an active field of research and there are several projects that aim at easier construction of SDFs and integration in 3D frameworks such as \href{https://github.com/Flafla2/Generic-Raymarch-Unity}{https://github.com/Flafla2/Generic-Raymarch-Unity} and \cite{lechner_hrtlacektdraymarchtoolkit_2020}.



\subsection{Motivation}
\label{subs:mot}
The reasons why sphere tracing in a compute shader for RIR estimation has not been documented until now probably lie in the relatively new introduction of compute shaders as well as in the difficulty of creating SDFs(in comparison to using existing 3D /CAD models and import them to polygon based ray tracers).
\subsubsection{Sphere tracing}
As described above, ray tracing in general is in use. Sphere tracing has a number of advantages over ray tracing polygonal surfaces. It is "procedural" by default, since all geometry is defined by implicit surface equations. More over sphere tracing approximates cone tracing for reducing aliasing artifacts in the pixel domain\cite{hart_sphere_1996}, which in the audio domain, is considered to have advantages but is very time confusing in a non-SDF setup\cite{alpkocak_computing_2010}. The deformation and rounding of geometry is possible in a very efficient way, which might offer an opportunity to approximate low-frequency response due to diffraction artifacts. Since geometry is not defined via vertizes and edges, there is no such thing as increasing the complexity of a shape in this way. Rounding a geometrical shape is a mere subtraction since it just shifts the rendering to another iso-surface, which is getting increasingly smooth as shown in \ref{sdf_2d_box}. Depending on the construction of the geometry, this way, holes and cavities (such as in a diffusor) can also be made disappear for a low-frequency pass as shown in figure \ref{fig:diffSmooth}.

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.6]{img/sdf2dbox.png}}
\caption{\label{sdf_2d_box}{\it rounding the box given in Equation \ref{eq:eq1} by subtraction of $0.7$. Visible iso-lines (gray) are generated by the distance function. The subtraction shifts the surface to a different, more round, iso-line.}}
\end{figure}  


\begin{figure}[ht]
\centering
\begin{subfigure}[t]{0.2\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{img/diffusorNorm.png}
  \caption{\it Diffusor shape}
  \label{fig:diffNorm}
\end{subfigure}%
\begin{subfigure}[t]{0.2\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{img/diffusorSmooth.png}
  \caption{\it After subtraction: rounded and closed.}
  \label{fig:sub2}
\end{subfigure}
\caption{\it The diffusor from scene 1 in \cite{brinkmann_round_2019} was reconstructed exactly(a). A subtraction of $0.01$ from the distance function causes the holes to close(b).}
\label{fig:diffSmooth}
\end{figure}

\subsubsection{Implementation}
It is possible to implement the chosen algorithm on the CPU and the GPU. A number of frameworks could be chosen for GPU accelerated computation such as OpenCL or NVIDIA CUDA. For example \cite{stoltzfus_performance_2017} gives an overview of GPU development environments suitable for RIR estimation. The choice of a shader has the advantage of being more operating system independent and hardware independent as for example the use of CUDA ties to NVIDIA GPUs. Compute shaders (in contrast to fragment shaders) make it possible to write to arbitrary output locations which is necessary for generating the actual impulse response from the measurement of timings. Since they are available since OpenGL 4.3 (August 2012) / OpenGL ES 3.1 they are both aged enough to have received broad support in other frameworks and relatively new in respect to first publications about sphere tracing. Another reason for the choice of compute shaders is their simplicity. In comparison to CUDA and OpenCL, shaders are easier to write and the use of the Graphics Library Shading Language (GLSL) is widespread. Achieving the whole computation, from the definition of the geometry, to the ray tracing up until the actual impulse response computation in a single shader makes this attempt highly portable and expandable.

\section{Generation of SDFs}

Only rather simplistic shapes where needed for this proof-of-concept. Mostly boxes are used and combined in various ways to achieve reflection areas, shoe-box scenes and the little more complex diffusor shape of scene 1 in \cite{brinkmann_round_2019}. A simple 3D box SDF with a size of $R_x$x$R_y$x$R_z$ can be described by:

\begin{equation}
  f(p_x, p_y, p_z) = \sqrt{c_0(p_x - R_x)^2 + c_0(p_y - R_y)^2 + c_0(p_z - R_z)^2}
  \label{eq:eq1}
\end{equation}

where $c_0$ is just clipping at 0:

\begin{equation}
c_0(x) = max(x,0) 
\end{equation}

which translates to GLSL conveniently:

\begin{lstlisting}[language=C, caption={\it GLSL code for creating a box SDF},captionpos=b, label=lst:boxSdf]
float box(vec3 pos, vec3 R){
    return length(max(abs(pos) - R,0));
}
\end{lstlisting}

\cite{hart_sphere_1996} gives a list mathematical definitions of many shapes and for example \href{http://mercury.sexy/hg_sdf/}{http://mercury.sexy/hg\_sdf/} provides a rich and advanced library of shapes and operators that are ready to use for creation of more complex scenery.


\section{Sphere Tracing}
For simplicity, deterministic equal-angle Ray Tracing is used in contrast to Monte Carlo or Equal Area Ray tracing (EART) \cite{gu_room_2014}. Unidirectional ray tracing has been used, also for simplicity reasons, although \cite{cao_interactive_2016} has shown that bidirectional ray tracing offers advantages. Since the classical sphere tracing algorithm was adapted, it was found to be simplest to consider the "camera" to be the receiver/microphone as it would receive light. It sends out rays that might hit the sound source, which acts as a receiver of rays. The sound source is chosen to be a sphere. Choosing a correct volume for the receiver is critical and using a constant size can introduce systematic errors \cite{xiangyang_accuracy_2003}, \cite{alpkocak_computing_2010}. A number of models are available to compute the receiver Volume, $V_r$. Typically factors such as room volume, number of rays and the distance from source are used for this computation. 
As in \cite{brandao_ray_nodate}, \cite{alpkocak_computing_2010}, and \cite{dalenback_room_1996} the receiver was allowed to grow in volume. While \cite{brandao_ray_nodate} and \cite{dalenback_room_1996} use time as a factor to let the receiver grow, in this attempt the reflection count, $k$ is used. Initially when a ray is sent, $k=1$ and when it hits a surface, this counter is increased by one so the source grows by this factor for this particular ray. So instead of using time, the model provided in \cite{alpkocak_computing_2010} is used and augmented with the $k$ term:
\begin{equation}
V_r = k \omega d_{SR}\sqrt{\frac{4}{N}}
\end{equation}
with 
\begin{equation}
\omega = log_{10}{V_{room}}
\end{equation}
where $d_{SR}$ is the source-receiver distance, $N$ is the number of initial rays and $V_{room}$ is the volume of the room.\

The actual sphere tracing largely follows the original formulation in \cite{hart_sphere_1996} and is implemented as:

% \begin{equation}
% t_{i+1} = t_i + F(t_i)
% \end{equation}
% With $t_{i}$  being the current distance travelled along the ray being used in combination with the evaluation of the distance function $F()$ 
Here, this is implemented in the following way:
\begin{lstlisting}[language=C, caption={\it GLSL pseudo code for sphere tracing},captionpos=b,label=lst:sphereTrace]
for (i=0;i++;i<imax){
  vec3 pos = ro + t*rd;
  Sdf res = map(pos);
  t += res.x;
  if(res.x<epsilon){
    break
  }
}
\end{lstlisting} 

In the above simplified code listing, \texttt{ro} is a \texttt{vec3} that defines the ray origin, \texttt{rd} the ray direction and \texttt{epsilon} can be set to adjust the algorithms precision. The \texttt{map()} function in this case not only returns the distance computed via the SDF(\texttt{res.x}) but a \texttt{struct} that can contain material properties (reflection coefficients etc.). Here it was used to distinguish between a sound source and a regular reflective body.
The space is sampled spherically and \texttt{rd} is generated from the compute shader's \texttt{gl\_GlobalInvocationID}.
From there, the space is sampled using the following very simplified pseudo code:
\begin{lstlisting}[language=C, caption={\it GLSL pseudo code for sampling the space and writing to the RIR.},captionpos=b, label=lst:mainloop]
Sdf res = castRay(ro,rd)
for (int k=0;k<numReflections;k++;){
  if(ComingFromReflectiveBdy){
    rd = relect(rd,normal);
  }
  res = castRay(ro,rd);
  t = res.x;
  pos = ro+rd*t;
  if(res.body == soundSource){
    travelDistance+=t;
    readWrite(travelDistance,k);
  }
}

\end{lstlisting}

Here, \texttt{castRay()} refers to a function that looks similar to the sphere tracing function above and \texttt{readWrite()} refers to a function that takes the total distance a ray has travelled from source to receiver including all reflections and the number of reflections. From the distance it computes the location where to write to in the impulse response and the attenuation. It then reads the current value at this location and adds the corresponding value, making use of a compute shader's capability to read and write it's output and write to arbitrary output locations. The necessity to write to arbitrary output locations is the main reason for choosing a compute shader over a fragment shader. But it is possible to define most of the functionality to in one file that is included to a compute shader to calculate the RIR and to a fragment shader for visualization. This is particularly handy during construction of geometry.


\begin{figure}[ht]
\center
\begin{tikzpicture}

\node (lib) at (0,0) [rectangle,draw] {$F(p_{xyz})$};
\node (frag) at (-2,-1) [rectangle,draw] {$fragment\ shader$};
\node (comp) at (2,-1) [rectangle,draw] {$compute\ shader$};
\draw node [block, below of=frag, node distance = 1.5cm](rend){\includegraphics[width=.1\textwidth]{img/diffusorNorm.png}};
\draw node [block, below of=comp, node distance = 1.5cm](H){$H(n)$};

\draw[->] (lib) -- node {} (frag);
\draw[->] (lib) -- node {} (comp);
\draw[->] (frag) -- node {}(rend);
\draw[->] (comp) -- node {}(H);



\end{tikzpicture}
\caption{\label{fig:bd_shaders}{\it A lot of the code, especially the map function, $F(p_{xyz})$, which contains the SDF can be shared between a fragment shader used for visualization and a compute shader responsible for RIR calculation.}}
\end{figure}



\begin{enumerate}
\item reflection
\item low frequency pass
\end{enumerate}


\section{impulse response Generation}
The room is assumed to be a linear time invariant (LTI) system. Due to the proof-of-concept nature of this proposal, a highly simplified model for RIR computation is used. Sphere tracing delivers distances and number of reflections for $M$ rays in this implementation. Each ray follows a number of reflections $K(m)$. Each reflection pass adds up to a total travel distance of the ray, $d(m)$. The sound source is assumed to send out a discrete impulse, the kronecker delta function, $\delta(n)$. As non-integer delays are ignored in this implementation, the shader will just write to the rounded integer delay location $\tau_s$ in the impulse response, $H(n)$,that corresponds to the distance:
\begin{equation}
H(n) = \sum_{m=0}^M \delta(n-\tau_s(m))\cdot \alpha(m)\cdot -1^{K(m)}
\end{equation}
The total attenuation per ray $\alpha(m)$ can be computed by using a material dependent coefficient of reflection $\alpha_{mat}$ that is stored in the \texttt{Sdf struct}. At each reflection pass $k$ this results in a possibly different reflection pass dependent coefficient $\alpha_{mat}(k,m)$ and keeping a running product in the loop of Listing \ref{lst:mainloop}:
\begin{equation}
\alpha(m)=\prod_{k=0}^{K(m)} \alpha_{mat}(k,m)
\end{equation}
For simplicity's sake, here only one global coefficient $\alpha_G$ is implemented resulting in:
\begin{equation}
\alpha(m) = \alpha_G^{K(m)}
\end{equation}

Additionally, a proof-of-concept for frequency dependent loss for each reflection is introduced into the model. As a computationally efficient heuristic, binomial filter is used \cite{aubury_binomial_1996}, \cite{derpanis_overview_nodate}. A simple one-zero filter $G(z)$ is applied at each reflection:

\begin{equation}
G(z,K) = (1+z^{-1})^K \cdot \frac{1}{2}^K
\end{equation}
The advantage of using such a simple filter is that a $K$-stage cascade's impulse response can be computed easily without applying the filter repeatedly. By doing the discrete time inverse fourier transform of the transfer function $G(z)$ the $N$-length impulse response is obtained:

\begin{equation}
  G(n,K) = \mathfrak{F}^{-1}\{ G(z) \} = (\frac{1}{2})^K \frac{1}{N}  \sum_{\omega = 0}^\pi (1+e^{-j\omega})^{K} e^{j\omega n} 
\end{equation}
A binomial filter's impulse response converges to a gaussian bell curve which can be approximated as:

\begin{equation}
G(n,K) \approx  \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot e ^{-\frac{1}{2} (\frac{n-\mu}{\sigma})^2}
\label{eq:assump}
\end{equation}


with 

\begin{equation}
\sigma = \sqrt{K 0.231 + 0.562}
\end{equation}
and 
\begin{equation}
\mu = \frac{K}{2} + \frac{1}{2}
\end{equation}

The right hand side of Equation \ref{eq:assump} is simply the normal distribution, which is computationally efficient to calculate for any $K$.

So instead of adding $\delta(n-\tau(m))$ into the IR, simply $G(n-\tau(m),K)$ is used. 
Similar to many other implementations, a high-pass filter is applied to the resulting RIR to compensate for low-frequency components resulting mainly from the spacial extendedness of the sound receiver shape.



\begin{figure*}[ht]
    \center
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/specBrink}
    \caption{\label{fig:fig:multReflSpecOrig} \it Original recording, scene 1, multiple reflections from \cite{brinkmann_round_2019}. }
    \end{subfigure}% 
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/simBrink}
      \caption{\label{fig:multReflSpecSim} \it Simulated using the proposed method. }
    \end{subfigure}
    \caption{\it Comparison of spectra of a real impulse response (a) and the proposed method (b).}
    \label{fig:multReflSpecCompare}
\end{figure*}


\section{Results}

\begin{figure*}[ht]
    \center
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/shoebox_orig}
    \caption{\label{fig:shoe} \it Spec by matlab. }
    \end{subfigure}% 
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/shoebox_sim}
      \caption{\label{fig:shoe} \it Simulated. }
    \end{subfigure}
    \caption{\it Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}.}
    \label{fig:test}
\end{figure*}


All of the following results have been computed with 10 reflection passes, and $1024^2$ rays. The computations were made on a strong consumer-grade machine (Intel i7 CPU, NVIDIA Geforce 1080ti). The computation time for simple scenes such as scene 1, rigid in \cite{brinkmann_round_2019} was at $<\frac{1}{60}$ seconds including the computation of a simple visualization in real time. The most complex scenes(geometrically and in regards to the amount of reflections) that where tested, the shoebox scene and scene 1 with added diffusor, where computed in less than $<\frac{1}{50}$ seconds. As expected, the method therefore outperforms CPU based methods in computation time.  \

The results are compared to a different simulation using the image source method \cite{lehmann_fast_2020} and \cite{brinkmann_round_2019} who generated a dataset featuring recordings in in an anechoic chamber with simple shapes. Note that for the comparison with \cite{brinkmann_round_2019} in figure \ref{fig:multRefl} ignores the frequency response of the speaker and microphone that was used in the original recording. As can be seen in the plot, the original recording features visible amount of difference to an ideal impulse even with the direct signal. 

Since this implementation lacks of features such as material-specific reflection coefficients and passes for multiple octave bands, it is not possible to accurately compare previous work with the proposed method by simply using the same materials. It can be shown that by adjusting reflection coefficients, the method can be matched up with existing work.

\begin{figure}

    \begin{center}
      \input{img/brink}
    \end{center}
    
    \caption{\label{fig:multRefl} \it RIR computed using the proposed method and measured by \cite{brinkmann_round_2019}, scene 3, multiple reflection at opposed MDF plates.}
\end{figure}

\begin{figure}
    \begin{center}
      \input{img/brinkDiff}
    \end{center}
    
    \caption{\label{fig:diffuser} \it RIR computed using the proposed method and measured by \cite{brinkmann_round_2019}, scene 1, a single reflection with a diffuser.}
\end{figure}


The shoebox scene features a small room with dimensions 3 x 4 x 2.5 meters. Note that \cite{lehmann_fast_2020} used a sampling rate of 16kHz and has been upsampled to 44.1 kHz for comparison reasons. This probably led to the pre-ringing artifacts present in Figure \ref{fig:shoe}.

\begin{figure}
    \begin{center}
      \input{img/shoebox}
    \end{center}
    \caption{\label{fig:shoe} \it Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
\end{figure}

\section{Conclusions and future work}
\label{sec:concl}

This work could show that RIR estimation via SDFs in a compute shader in real-time compatible manner is possible. It remains to be tested how far this method can reach. While it still is computationally costly to do these calculations in general, the use of SDFs can offer some significant advantages such as their procedural nature, their efficiency and simplicity. A number of improvements both in speed and are possible in the proposed technique, such as material dependent attenuation and scattering for example. Also, a number of speed improvements and optimizations could be implemented such as the removal of if statements in the SDF function. Furthermore a more detailed comparison and more mature and rigorous mathematical analysis of the process seems promising as well as an analysis of the sphere-tracing-specific artifacts and their effects in the audio domain. As mentioned in Section \ref{subs:mot}, sphere-tracing seems to offer a stunning simplicity for example when it comes to smoothing geometry. Simply the fact that it is a rather different approach than classical ray casting of polygons seems to promise opportunities for optimization. 

An SDF's closeness to classical mathematical structures (in contrast to sets of triangles, vertices, edges etc.) might lead to easier analysis or simpler comparison of different algorithms. Their popularity in the graphics community leads to constant development and the shier activity in the field seems to promise greater ease of use in the future. \

Certain rather experimental ideas also are easy to realize in this technique. Due to the aforementioned connection between geometry formulation in sphere tracing and mathematical formulas, this algorithm is often used to render fractals. In this context this would mean that it is rather easy to calculate the RIR of a menger sponge or a Julia Set. Moreover, many geometries/SDFs can be formulated in a dimension independent way, resulting in a straight forward way to render 4-dimensional geometries, leading to the idea of calculating the RIR of a 4-dimensional room. While these thoughts don't offer any apparent practical application and might "only" lead to aesthetically interesting results, it is possible to find applications in the sonification of high dimensional data.

% Please, submit full-length papers (max.~8 pages both oral and poster presentations).
% Submission is fully electronic and automated through the Conference Web Submission System.
% DO NOT send us papers directly by e-mail.

\section{Acknowledgments}
This work was supported in part by the university of Applied sciences St.Poelten.
% Thanks to inigo quilez, the shadertoy community.
% Many thanks to the great number of anonymous reviewers!

%\newpage
\nocite{*}
\bibliographystyle{IEEEbib}
\bibliography{RaymarchReverb2}


\end{document}





% \begin{figure}
%     \begin{center}
%       \input{img/normDist}
%         % \input{img/mytikz.tex}
%     \end{center}
%     \caption{A PGF histogram from \texttt{matplotlib}.}
% \end{figure}


% Advantage of compute shader.
% Maybe introduce cascaded Lowpass.



% All figures should be centred on the column (or page, if the figure spans both columns).
% Figure captions (in italic) should follow each figure and have the format given in Figure \ref{fft_plot}.
% %
% Vectorial figures are preferred. For example when using
% \texttt{Matlab}, export using either Postscript or PDF format. Also,
% in order to provide a better readability, figure text font size
% should be at least identical to footnote font size. To do so using
% \texttt{Matlab}, use the \texttt{subplot} command before plotting.
% If bitmap figures are used, please make sure that the resolution is
% enough for print quality. Fig. \ref{ftt_plot2} illustrates an
% example of a figure spanning two columns.
%


% \begin{figure}
%     \begin{center}
%       \input{img/spec1}
%     \end{center}
%     \caption{\label{fig:shoe} \it Spec by this approach. Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
% \end{figure}



% \begin{figure}
%     \begin{center}
%       \input{img/orig}
%     \end{center}
%     \caption{\label{fig:shoe} \it Spec by matlab. Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
% \end{figure}


% \begin{figure}
%     \begin{center}
%       \input{img/specBrink}
%     \end{center}
%     \caption{\label{fig:shoe} \it Original \cite{brinkmann_round_2019}. }
    
% \end{figure}


% \begin{figure}
%     \begin{center}
%       \input{img/simBrink}
%     \end{center}
%     \caption{\label{fig:shoe} \it Simulated. }
    
% \end{figure}

% \begin{enumerate}



% Eric A. Lehmann (2020). Fast simulation of acoustic room impulse responses (image-source method) (https://www.mathworks.com/matlabcentral/fileexchange/25965-fast-simulation-of-acoustic-room-impulse-responses-image-source-method), MATLAB Central File Exchange. Retrieved February 14, 2020.

% \end{enumerate}


% \begin{figure}[ht]
% \centerline{\includegraphics[scale=0.8]{fft_plot2}}
% \caption{\label{fft_plot}{\it Sinusoid in time and frequency domain. Short captions are centred, long captions (more than 1 line) are justified.}}
% \end{figure}
% %
% \begin{figure*}[ht]
% \center
% \includegraphics[width=5in]{TwoColumnSine2}
% \caption{\label{ftt_plot2}{\it A figure spanning two columns, as mentioned in Sec. . }}
% \end{figure*}


% \begin{figure}[ht]
% \centerline{\includegraphics[scale=0.8]{img/test1.pgf}}
% \caption{\label{fft_plot}{\it Sinusoid in time and frequency domain. Short captions are centred, long captions (more than 1 line) are justified.}}
% \end{figure}

% \begin{figure}
%     \begin{center}
%       \input{img/ir_sc3_rigid_0}
%         % \input{img/mytikz.tex}
%     \end{center}
%     \caption{A PGF histogram from \texttt{matplotlib}.}
% \end{figure}




% \subsection{Tables}
% As for figures, all tables should be centered on the column (or page, if the table spans both columns).
% Table captions should be in italic, precede each table and have the format given in Table \ref{tab:example}.

% \begin{table}[ht]
%   \caption{\itshape Basic trigonometric values.}
%   \centering
%   \begin{tabular}{|c|c|}
%     \hline
%     $\mathrm{angle}\,(\theta, \mathrm{rad})$ & $\sin \theta$ \\\hline
%     $\frac{\pi}{2}$ & $1$ \\
%     $\pi$ & $0$ \\
%     $\frac{3\pi}{2}$ & $-1$ \\
%     $2\pi$ & $0$ \\\hline
%   \end{tabular}
%   %
%   \label{tab:example}
% \end{table}

% \begin{table*}[ht]
%   \caption{{\it Basic trigonometric values, spanning two columns.}}
%   \centering
%   \begin{tabular}{|c|c|c|c|c|c|c|}\hline
%     $\mathrm{angle}\, (\theta, \mathrm{rad})$ & $\sin \theta$ & $\cos \theta $ & $(\sin \theta)/2 $ & $(\cos \theta) /2 $ & $(\sin \theta)/3 $ & $(\cos \theta)/3$    \\\hline
%     $\frac{\pi}{2}$ & $1$ & $0$ & $1/2$ & $0$ & $1/3$ & $0$ \\
%     $\pi$ & $0$ & $-1$ & $0$ & $-1/2$ & $0$ & $-1/3$\\
%     $\frac{3\pi}{2}$ & $-1$ & $0$ & $-1/2$ & $0$ & $-1/3$ & $0$ \\
%     $2\pi$ & $0$ & $1$ & $0$ & $1/2$ & $0$ & $1/3$ \\\hline
%  \end{tabular}
%   %
%   \label{tab:example2}
% \end{table*}

% \subsection{Equations}
% Equations should be placed on separate lines and numbered:

% \begin{equation}
%   X(e^{j\Omega})=\sum_{n=0}^{N-1}x(n)e^{-j\Omega n}
%   \label{eq1}
%   \end{equation}
%   where the sequence $x(n)$ in equation (\ref{eq1}) is a windowed frame:
%   \begin{equation}
%   x(n)=s(n) w(n)
%   \label{eq2}
% \end{equation}
% %
% with a window function $w(n)$.
