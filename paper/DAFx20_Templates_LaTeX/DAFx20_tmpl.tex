% Template LaTeX file for DAFx-20 papers
%
% To generate the correct references using BibTeX, run
%     latex, bibtex, latex, latex
% modified...
% - from DAFx-00 to DAFx-02 by Florian Keiler, 2002-07-08
% - from DAFx-03 to DAFx-04 by Gianpaolo Evangelista, 2004-02-07 
% - from DAFx-05 to DAFx-06 by Vincent Verfaille, 2006-02-05
% - from DAFx-06 to DAFx-07 by Vincent Verfaille, 2007-01-05
%                          and Sylvain Marchand, 2007-01-31
% - from DAFx-07 to DAFx-08 by Henri Penttinen, 2007-12-12
%                          and Jyri Pakarinen 2008-01-28
% - from DAFx-08 to DAFx-09 by Giorgio Prandi, Fabio Antonacci 2008-10-03
% - from DAFx-09 to DAFx-10 by Hannes Pomberger 2010-02-01
% - from DAFx-10 to DAFx-12 by Jez Wells 2011
% - from DAFx-12 to DAFx-14 by Sascha Disch 2013
% - from DAFx-15 to DAFx-16 by Pavel Rajmic 2015
% - from DAFx-16 to DAFx-17 by Brian Hamilton 2016
% - from DAFx-17 to DAFx-18 by Annibal Ferreira and Matthew Davies 2017
% - from DAFx-18 to DAFx-19 by Dave Moffat 2019
% - from DAFx-19 to DAFx-20 by Gianpaolo Evangelista 2019
%
% Template with hyper-references (links) active after conversion to pdf
% (with the distiller) or if compiled with pdflatex.
%
% 20060205: added package 'hypcap' to correct hyperlinks to figures and tables
%                      use of \papertitle and \paperauthorA, etc for same title in PDF and Metadata
% 20190205: Package 'hypcap' removed, and replaced with 'caption', to allow for the inclusion
%			of a CC UP licence.
%
% 1) Please compile using latex or pdflatex.
% 2) If using pdflatex, you need your figures in a file format other than eps! e.g. png or jpg is working
% 3) Please use "paperftitle" and "pdfauthor" definitions below

%------------------------------------------------------------------------------------------
%  !  !  !  !  !  !  !  !  !  !  !  ! user defined variables  !  !  !  !  !  !  !  !  !  !  !  !  !  !
% Please use the following commands to define title and author(s) of the paper.
% paperauthorA MUST be the the first author of the paper
% Please comment the unused definitions 
\def\papertitle{Room Impulse Response Estimation using Signed Distance Functions}
\def\paperauthorA{Patrik Lechner}
% \def\paperauthorB{Author Two}
% \def\paperauthorC{Author Three}
% \def\paperauthorD{Author Four}
%\def\paperauthorE{Author Five}
%\def\paperauthorF{Author Six}
%\def\paperauthorG{Author Seven}
%\def\paperauthorH{Author Eight}
%\def\paperauthorI{Author Nine}
%\def\paperauthorJ{Author Ten}

% Authors' affiliations have to be set below

%------------------------------------------------------------------------------------------
\documentclass[twoside,a4paper]{article}
\usepackage{etoolbox}
\usepackage{dafx_20}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{euscript}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{lmodern}
\usepackage{nimbusserif}
\usepackage{ifpdf}
\usepackage[english]{babel}
\usepackage{caption}
% \usepackage{subfig} % or can use subcaption package
\usepackage{color}

\input glyphtounicode
\pdfgentounicode=1

\setcounter{page}{1}
\ninept

% build the list of authors and set the flag \multipleauth to handle the et al. in the copyright note (in DAFx_20.sty)
%==============================DO NOT MODIFY =======================================
\newcounter{numauth}\setcounter{numauth}{1}
\newcounter{listcnt}\setcounter{listcnt}{1}
\newcommand\authcnt[1]{\ifdefined#1 \stepcounter{numauth} \fi}

\newcommand\addauth[1]{
\ifdefined#1 
\stepcounter{listcnt}
\ifnum \value{listcnt}<\value{numauth}
\appto\authorslist{, #1}
\else
\appto\authorslist{~and~#1}
\fi
\fi}
%======DO NOT MODIFY UNLESS YOUR PAPER HAS MORE THAN 10 AUTHORS========================
%==we count the authors defined at the beginning of the file (paperauthorA is mandatory and already accounted for)
\authcnt{\paperauthorB}
\authcnt{\paperauthorC}
\authcnt{\paperauthorD}
\authcnt{\paperauthorE}
\authcnt{\paperauthorF}
\authcnt{\paperauthorG}
\authcnt{\paperauthorH}
\authcnt{\paperauthorI}
\authcnt{\paperauthorJ}
%==we create a list of authors for pdf tagging, for example: paperauthorA, paperauthorB, ... and paperauthorF (last author)
\def\authorslist{\paperauthorA}
\addauth{\paperauthorB}
\addauth{\paperauthorC}
\addauth{\paperauthorD}
\addauth{\paperauthorE}
\addauth{\paperauthorF}
\addauth{\paperauthorG}
\addauth{\paperauthorH}
\addauth{\paperauthorI}
\addauth{\paperauthorJ}
%====================================================================================

\usepackage{times}
% Saves a lot of ouptut space in PDF... after conversion with the distiller
% Delete if you cannot get PS fonts working on your system.


% pdf-tex settings: detect automatically if run by latex or pdflatex
\newif\ifpdf
\ifx\pdfoutput\relax
\else
   \ifcase\pdfoutput
      \pdffalse
   \else
      \pdftrue
\fi

\ifpdf % compiling with pdflatex
  \usepackage[pdftex,
    pdftitle={\papertitle},
    pdfauthor={\authorslist},
    pdfsubject={Proceedings of the 23rd International Conference on Digital Audio Effects (DAFx-20)},
    colorlinks=false, % links are activated as color boxes instead of color text
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen; especially useful if working with a big screen :-)
  ]{hyperref}
  \pdfcompresslevel=9
  \usepackage[pdftex]{graphicx}
 % \usepackage[figure,table]{hypcap}
\else % compiling with latex
  \usepackage[dvips]{epsfig,graphicx}
  \usepackage[dvips,
    pdftitle={\papertitle},
    pdfauthor={\authorslist},
    pdfsubject={Proceedings of the 23rd International Conference on Digital Audio Effects (DAFx-20)},
    colorlinks=false, % no color links
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen
  ]{hyperref}
  % hyperrefs are active in the pdf file after conversion
  %\usepackage[figure,table]{hypcap}
\fi
\usepackage[hypcap=true]{caption}
\title{\papertitle}

% -------------SINGLE-AFFILIATION SINGLE-AUTHOR HEADER STARTS (uncomment below if your paper has a single author)----------------------------------------
\affiliation{
\paperauthorA\,\thanks{\vspace{-3mm}}}
{\href{https://www.mdw.ac.at/ike/}{Institute of Creative\textbackslash Media/Technologies} \\ University of Applied Sciences St.Poelten\\ St.Poelten, Austria\\
{\tt \href{mailto:dafx2020@gmail.com}{ptrk.lechner@gmail.com}}
}
%-------------SINGLE-AFFILIATION SINGLE-AUTHOR HEADER ENDS-------------------------------------------------------------------------------------------------------------------

%------------SINGLE-AFFILIATION MULTIPLE-AUTHORS HEADER STARTS (uncomment below if your paper has two or more authors from the same institution)
% \affiliation{
% \paperauthorA\,\sthanks{Thanks to the predecessors for the templates}and \paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
% {\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
% {\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
% }
%-----------------------------------SINGLE-AFFILIATION-MULTIPLE-AUTHORS HEADER ENDS----------------------------------------------------------------------------------------

%---------------TWO-AFFILIATIONS HEADER STARTS (uncomment below if your paper has two authors, each from a different institution)-----------------------------
%\twoaffiliations{
%\paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
%{\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
%{\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
%}
%{\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
%{\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
%}
%-------------------------------------TWO-AFFILIATIONS HEADER ENDS------------------------------------------------------

%%---------------THREE-AFFILIATIONS HEADER STARTS (uncomment below if your paper has three authors, each from a different institution)-----------------------
%\threeaffiliations{
%\paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
%{\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
%{\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
%}
%{\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
%{\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
%}
%{\paperauthorC \,\sthanks{Illustrious contributor}}
%{\href{http://dafx2018.web.ua.pt/}{IEETA} \\ University of Aveiro \\ Aveiro, Portugal \\ {\tt \href{mailto:dafx2018_papers@ua.pt}{dafx2018\_papers@ua.pt}}
%}
%-------------------------------------THREE-AFFILIATIONS HEADER ENDS------------------------------------------------------

%----------------FOUR-AFFILIATIONS HEADER STARTS (uncomment below if your paper has four authors, , each from a different institution)-----------------------
% \fouraffiliations{
% \paperauthorA \,\sthanks{Thanks to the predecessors for the templates}}
% {\href{https://www.mdw.ac.at/ike/}{Institute 1} \\ University of Music and Performing Arts\\ Vienna, Austria\\
% {\tt \href{mailto:dafx2020@gmail.com}{dafx2020@gmail.com}}
% }
% {\paperauthorB \,\sthanks{This work was supported by the XYZ Foundation}}
% {\href{http://dafx2019.bcu.ac.uk/}{Digital Media Technology Lab} \\ Birmingham City University \\ Birmingham, UK \\ {\tt \href{mailto:dafx2019@gmail.com}{dafx2019@gmail.com}}
% }
% {\paperauthorC \,\sthanks{Illustrious contributor}}
% {\href{http://dafx2018.web.ua.pt/}{IEETA} \\ University of Aveiro \\ Aveiro, Portugal \\ {\tt \href{mailto:dafx2018_papers@ua.pt}{dafx2018\_papers@ua.pt}}
% }
% {\paperauthorD \,\sthanks{This guy is a very good fellow}}
% {\href{http://www.acoustics.ed.ac.uk}{Acoustics and Audio Group} \\ University of Edinburgh\\ Edinburgh, UK\\ {\tt \href{mailto:dafx17@ed.ac.uk}{dafx17@ed.ac.uk}}
% }
%-------------------------------------FOUR-AFFILIATIONS HEADER ENDS------------------------------------------------------



% ============MY ADDITIONS ====================

\hyphenpenalty=10000
\hbadness=10000

\usepackage{pgf}
% -----------plotting with tikz-------
\usepackage{tikz}
\usepackage[utf8]{inputenc}
% \usepackage{fontspec}  % optional
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{dateplot}

% \usepgfplotslibrary{external} 
% \tikzexternalize
% ------------------------------------

% code
\usepackage{listings}
\lstset
{
frame = single,
}
% \lstset
% { %Formatting for code in appendix
%     % language=Matlab,
%     % basicstyle=\footnotesize,
%     numbers=left,
%     stepnumber=1,
%     showstringspaces=false,
%     tabsize=1,
%     breaklines=true,
%     breakatwhitespace=false,
% }

% subfigures (side by side)
\usepackage{subcaption}
% \usepackage{subfig}




% =============== BlockDiagram Drawing Config
\usetikzlibrary{shapes,arrows}
  \usetikzlibrary{trees, backgrounds}

% Definition of blocks:
\tikzset{%
  block/.style    = {draw, thick, rectangle, minimum height = 3em,
    minimum width = 3em},
  sum/.style      = {draw, circle, node distance = 2cm}, % Adder
  input/.style    = {coordinate}, % Input
  output/.style   = {coordinate}, % Output
  mult/.style   = {draw, isosceles triangle, minimum height=1cm, minimum width =1cm}
}
% mult/.style   = {isosceles triangle, sharp corners, anchor=center, xshift=-4mm, minimum height=1.5cm, minimum width =0.05cm}
%isosceles triangle, fill=gray!25, minimum width=1.5cm

% Defining string as labels of certain blocks.
\newcommand{\suma}{\Large$+$}
\newcommand{\inte}{$\displaystyle \int$}
\newcommand{\derv}{\huge$\frac{d}{dt}$}
\newcommand{\conv}{\huge$\ast$}

% ==

% ====================================


\setlength{\emergencystretch}{3em}



\begin{document}
% more pdf-tex settings:
\ifpdf % used graphic file format for pdflatex
  \DeclareGraphicsExtensions{.png,.jpg,.pdf}
\else  % used graphic file format for latex
  \DeclareGraphicsExtensions{.eps}
\fi

%\makeatletter
%\pdfbookmark[0]{\@pdftitle}{title}
%\makeatother

\maketitle

\begin{abstract}

There are several algorithms and approaches to Room Impulse Response (RIR) estimation. To the best of the author's knowledge, there is no documentation of accuracy, speed, or even the feasibility of using signed distance functions (SDFs) in combination with sphere tracing for this task. A proof of concept with a focus on real-time performance is presented here, which still lacks many features such as frequency-dependent absorption and scattering coefficients, arbitrary source and receiver directives etc. The results are then compared to real room impulse responses and to a different simulation algorithm. Also, the rather special merits of such an approach, such as 4D reverberation and simple rounding of geometry, are briefly discussed and presented. 


\end{abstract}

\section{Introduction}
\label{sec:intro}
Sphere tracing as defined by \cite{hart_sphere_1996} has been used extensively in the so-called "demo scene" for decades to render 3D video demos via shaders in real time. 
Sphere tracing is a version of the ray casting algorithm \cite{roth_ray_1982}. It relies on the geometry being defined as signed distance functions (SDFs), and does not directly support the import of standard 3D Polygonal geometry or meshes. One of the advantages lies in the algorithm's potentially improved speed in comparison to fixed-step ray casting. SDFs are used to describe implicit surfaces, typically via a function $f : \mathbb{R}^3 \rightarrow \mathbb{R}$(although in principle, arbitrary dimensions are possible, $f : \mathbb{R}^n \rightarrow \mathbb{R}$. See Section \ref{sec:concl}). In order to define the desired geometry, this $f$ should be designed to return a negative value if the locus of the point is inside the geometry, a positive value if the locus is outside and 0 if on the surface. 
% Additionally it is considered advantageous to design this function in such a way that it is Lipschitz continuous \cite{hart_sphere_1996}. 
If $f$ is defined carefully, the distance to the nearest surface is returned by the function and therefore always known during stepping along a view-ray. 
It follows from this that the step size of a ray casting algorithm can be dynamically adjusted (see Figure \ref{sphereViz}), resulting in fewer iterations along a ray, and therefore in significant speed-ups. This dynamic adjustment of the step size to unbound spheres around the current step is the core idea of sphere tracing and the reason for its name \cite{hart_sphere_1996}. \\
Throughout this paper, several test-scenes are mentioned such as "scene 1, rigid". These scenes are taken from \cite{brinkmann_round_2019} which attempts to compare different RIR algorithms with real recordings. For this purpose, real rooms have been measured and CAD models are provided of these scenes. Therefore this work used a small set of simple scenes from \cite{brinkmann_round_2019} and repeatedly refers to them.

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.5]{img/sphereTracingViz.png}}
\caption{\label{sphereViz}{\it Visualization of the sphere tracing algorithm in 2D. A ray is sent from the source (left) to the right until it hits a surface, always moving the maximum distance as the SDF informs the tracing algorithm about the distance to the nearest surface.}}
\end{figure}

\subsection{Previous Work}
\label{ssec:prev}
A lot of previous work exists both in the field of ray/sphere tracing and RIR estimation.
As shown in \cite{alpkocak_computing_2010} and \cite{brinkmann_round_2019}, there are numerous approaches for estimating RIRs. Besides ray-based methods such as the "Image Source Method", ray-tracing and hybrid approaches, wave-based methods, such as finite difference methods are becoming increasingly interesting due to advancements in computational power and research. Still, wave-based methods seem to be too slow for real-time applications. With the Pascal Architecture, NVIDIA introduced real-time ray tracing done on the GPU with NVIDIA VRWorks™ Audio \cite{noauthor_vrworks_nodate}.

% NVIDIA is working in the field of real time ray traced audio simulation
% NVIDIA VRWorks™ Audio (introduced with the Pascal GPU architecture) 



% \subsubsection*{RIR Estimation}
% \cite{alpkocak_computing_2010} gives an overview of methods in use for RIR estimation.


\subsubsection*{Sphere Tracing}
Sphere tracing itself was first described by \cite{hart_sphere_1996}. Since then, many authors have described improvements in speed e.g. \cite{balint_accelerating_2018} or the addition of features such as \cite{quilez_inigo_nodate} \cite{sawhney_monte_2020}, \cite{keinert_enhanced_2014} or the activity of the "shadertoy"-community\cite{quilez_shadertoy_nodate}.
The defining of SDFs is an active field of research and there are several projects that aim at easier construction of SDFs and integration in 3D frameworks such as \cite{SDFunity}  and \cite{lechner_hrtlacektdraymarchtoolkit_2020} but 
also some commercial software products have implemented raymarching and SDFs by default such as \texttt{Houdini} or \texttt{Notch}.



\subsection{Motivation}
\label{subs:mot}
The reasons why sphere tracing in a compute shader for RIR estimation has not been documented until now probably lie in the relatively new introduction of compute shaders as well as in the difficulty of creating SDFs (in comparison to using existing 3D /CAD models and importing them to polygon-based ray tracers).
\subsubsection{Sphere Tracing}
As described above, ray tracing is one common method of approaching the problem of RIR estimation. Sphere tracing offers a number of advantages over ray tracing in combination with meshes or polygonal surfaces. It is procedural/parametric by default, since all geometry is defined by implicit surface equations. Sphere tracing approximates cone tracing and is thereby reducing aliasing artifacts in the pixel domain\cite{hart_sphere_1996}. In the audio domain, beam tracing is considered to have advantages- however, it is is very time consuming in a non-SDF setup\cite{alpkocak_computing_2010}. Deformation and rounding of geometry is possible in a very efficient way, which might offer an opportunity to approximate low-frequency response due to diffraction artifacts. Since geometry is not defined via vertices and edges, there is no such thing as increasing the complexity of a shape in this way as in traditional mesh-based approaches. Rounding a geometrical shape is a mere subtraction since it just shifts the rendering to another iso-surface which gets increasingly smooth as shown in Figure \ref{sdf_2d_box}. Depending on the construction of the geometry, holes and cavities (such as in a diffusor) can also be made to disappear (offering ideas for heuristics for a low-frequency pass), as shown in Figure \ref{fig:diffSmooth}.

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.6]{img/sdf2dbox.png}}
\caption{\label{sdf_2d_box}{\it Rounding the box given in Equation \ref{eq:eq1} by subtraction of $0.7$meters. Visible iso-lines (gray) are generated by the distance function. The subtraction shifts the surface to a different, rounder iso-line.}}
\end{figure}  


\begin{figure}[ht]
\centering
\begin{subfigure}[t]{0.2\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{img/diffusorNorm.png}
  \caption{\it Diffusor shape}
  \label{fig:diffNorm}
\end{subfigure}%
\begin{subfigure}[t]{0.2\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{img/diffusorSmooth.png}
  \caption{\it After subtraction: rounded and closed.}
  \label{fig:sub2}
\end{subfigure}
\caption{\it The diffusor from scene 1 in \cite{brinkmann_round_2019} was reconstructed exactly (a). A subtraction of $0.01$meters from the distance function causes the holes to close (b).}
\label{fig:diffSmooth}
\end{figure}

\subsubsection{Implementation}
It is possible to implement the chosen algorithm on the CPU and the GPU. A number of frameworks could be chosen for GPU-accelerated computation such as OpenCL or NVIDIA CUDA. For example, \cite{stoltzfus_performance_2017} gives an overview of GPU development environments suitable for RIR estimation. The choice of a shader has the advantage of being more operating system-independent and hardware-independent as, for example, the use of CUDA ties to NVIDIA GPUs. Compute shaders (in contrast to fragment shaders) make it possible to write to arbitrary output locations, which is necessary for generating the actual impulse response from the measurement of timings. Since they have been available since OpenGL 4.3 (August 2012) / OpenGL ES 3.1, they are both mature enough to have received broad support in other frameworks, and relatively new in respect to first publications about sphere tracing. Another reason for the choice of compute shaders is their simplicity. In comparison to CUDA and OpenCL, shaders are easier to write and the use of the Graphics Library Shading Language (GLSL) is widespread. Achieving the whole computation in a single shader, from the definition of the geometry, to the ray tracing, up until the actual impulse response computation makes this attempt highly portable and expandable.

\section{Generation of SDFs}

Only rather simplistic shapes were needed for this proof of concept. Predominantly boxes were used and combined in various ways to achieve reflection areas, shoe-box scenes and the slightly more complex diffusor shape of scene 1 in \cite{brinkmann_round_2019}. A simple 3D box SDF $f$ as a function of 3-dimensional coordinates $p_x, p_y, p_z$ with a size of $R_x\times R_y \times R_z$ can be described by:

\begin{equation}
  f(p_x, p_y, p_z) = \sqrt{c_0(p_x - R_x)^2 + c_0(p_y - R_y)^2 + c_0(p_z - R_z)^2}
  \label{eq:eq1}
\end{equation}

where the function $c_0(x)$ is just clipping at 0:

\begin{equation}
c_0(x) = max(x,0) 
\end{equation}

which conveniently translates to GLSL:

\begin{lstlisting}[language=C, caption={\it GLSL code for creating a box SDF},captionpos=b, label=lst:boxSdf]
float box(vec3 pos, vec3 R){
    return length(max(abs(pos) - R,0));
}
\end{lstlisting}
As mentioned above, rounding can be achieved by subtracting a distance value (in meters in this case since all distances in this implementation are chosen to be in meters). As an example, this is demonstrated in Figure \ref{sdf_2d_box}, with the value 0.7meters resulting in $f_r$:
\begin{equation}
f_r(p_x, p_y, p_z) = f(p_x, p_y, p_z)-0.7m
\end{equation}

\cite{hart_sphere_1996} gives a list of mathematical definitions of many shapes, \cite{diener_procedural_2012} gives a good overview of procedural modeling using SDFs and a rich and advanced  software library of shapes and operators that are ready to use for the creation of more complex scenery can be found in the \texttt{mercury hg\_sdf library}\cite{mercury}.


\section{Sphere Tracing}
For simplicity, deterministic equal-angle Ray Tracing is used in contrast to Monte Carlo or Equal Area Ray Tracing (EART) \cite{gu_room_2014}. Unidirectional ray tracing has also been used for simplicity reasons, although \cite{cao_interactive_2016} has shown that bidirectional ray tracing offers advantages. Since the classical sphere tracing algorithm was adapted, it was found to be simplest to consider the "camera" to be the receiver/microphone as it would receive light. It sends out rays that might hit the sound source, which acts as a receiver of rays. The sound source is chosen to be a sphere. Choosing the correct volume for the receiver is critical, and using a constant size can introduce systematic errors \cite{xiangyang_accuracy_2003}, \cite{alpkocak_computing_2010}. A number of models are available to compute the receiver volume, $V_r$. Typically factors such as room volume, the number of rays and the distance from the source are used for this computation. 
As in \cite{brandao_ray_nodate}, \cite{alpkocak_computing_2010}, and \cite{dalenback_room_1996}, the receiver was allowed to grow in volume. While \cite{brandao_ray_nodate} and \cite{dalenback_room_1996} use time as a factor to let the receiver grow, the reflection count $k$ is used in this attempt. Initially, when a ray is sent, $k=0$ and when it hits a surface, this counter is increased by one so the source grows by this factor for this particular ray. So instead of using time, the model provided in \cite{alpkocak_computing_2010} is used and augmented with the $k$ term:
\begin{equation}
V_r = (k+1) \omega d_{SR}\sqrt{\frac{4}{N}}
\end{equation}
with 
\begin{equation}
\omega = log_{10}{V_{room}}
\end{equation}
where $d_{SR}$ is the source-receiver distance, $N$ is the number of initial rays and $V_{room}$ is the volume of the room.\

The actual sphere tracing largely follows the original formulation in \cite{hart_sphere_1996} and is implemented similar to the pseudo code in Listing \ref{lst:sphereTrace}.

% \begin{equation}
% t_{i+1} = t_i + F(t_i)
% \end{equation}
% With $t_{i}$  being the current distance travelled along the ray being used in combination with the evaluation of the distance function $F()$ 
\begin{lstlisting}[language=C, caption={\it GLSL pseudo code for sphere tracing},captionpos=b,label=lst:sphereTrace]
for (i=0;i++;i<imax){
  vec3 pos = ro + t*rd;
  Sdf res = map(pos);
  t += res.x;
  if(res.x<epsilon){
    break
  }
}
\end{lstlisting} 

In the above simplified code listing, the variable \texttt{ro} defines the ray origin in space, \texttt{rd} defines the ray direction and \texttt{epsilon} can be set to adjust the algorithm's precision. The \texttt{map()} function in this case not only returns the distance computed via the SDF(\texttt{res.x}) but a \texttt{struct} that can contain material properties (reflection coefficients, etc.). Here it was used to distinguish between a sound source and a regular reflective body.
The space is sampled spherically and \texttt{rd} is generated from the compute shader's \texttt{gl\_GlobalInvocationID}. In this implementation, a resolution of $1024 \times 1024$ is used, resulting in $1024^2$ initial rays and a maximum RIR length of $1024^2$ samples.
From there, the space is sampled using the highly simplified pseudo code in Listing \ref{lst:mainloop}.


% \begin{minipage}[float,floatplacement=H]


\begin{lstlisting}[float,floatplacement=H, language=C, caption={\it GLSL pseudo code for sampling the space and writing to the RIR.},captionpos=b, label=lst:mainloop]
Sdf res = castRay(ro,rd)
for (int k=0;k<numReflections;k++;){
  if(ComingFromReflectiveBdy){
    rd = reflect(rd,normal);
  }
  res = castRay(ro,rd);
  t = res.x;
  pos = ro+rd*t;
  if(res.body == soundSource){
    travelDistance+=t;
    readWrite(travelDistance,k);
  }
}

\end{lstlisting}
% \end{minipage}

In Listing \ref{lst:mainloop}, \texttt{castRay()} refers to a function that looks similar to the sphere tracing function in Listing \ref{lst:sphereTrace}, and \texttt{readWrite()} refers to a function that takes the total distance a ray has traveled from source to receiver, including all reflections and the number of reflections. From the distance it computes the location to write to in the impulse response and the attenuation. It then reads the current value at this location and adds the corresponding value, making use of a compute shader's capability to read and write its output and write to arbitrary output locations. The necessity to write to arbitrary output locations is the main reason for choosing a compute shader over a fragment shader. It is, however, possible to define most of the functionality in one file that is referenced via an \texttt{include} statement into a compute shader to calculate the RIR and into a fragment shader for visualization, see Figure \ref{fig:bd_shaders}. This is particularly handy during the construction of geometry but also makes it possible to easily calculate the RIR of existing sphere-traced scenes for reverberation, e.g. in an audio/visual performance context or for other 3D video content.


\begin{figure}[ht]
\center
\begin{tikzpicture}

\node (lib) at (0,0) [rectangle,draw] {$F(p_{xyz})$};
\node (frag) at (-2,-1) [rectangle,draw] {$fragment\ shader$};
\node (comp) at (2,-1) [rectangle,draw] {$compute\ shader$};
\draw node [block, below of=frag, node distance = 1.5cm](rend){\includegraphics[width=.1\textwidth]{img/diffusorNorm.png}};
\draw node [block, below of=comp, node distance = 1.5cm](H){$H(n)$};

\draw[->] (lib) -- node {} (frag);
\draw[->] (lib) -- node {} (comp);
\draw[->] (frag) -- node {}(rend);
\draw[->] (comp) -- node {}(H);



\end{tikzpicture}
\caption{\label{fig:bd_shaders}{\it A lot of the code, especially the map function $F(p_{xyz})$ which contains the SDF, can be shared between a fragment shader used for visualization and a compute shader responsible for RIR calculation.}}
\end{figure}



% \begin{enumerate}
% \item reflection
% \item low frequency pass
% \end{enumerate}


\section{impulse response Generation}
The room is assumed to be a linear time-invariant (LTI) system. Due to the proof-of-concept nature of this proposal, a highly simplified model for RIR computation is used. Sphere tracing delivers the distances and number of reflections for $M$ rays in this implementation. Each ray follows a number of reflections $K(m)$. Each reflection pass adds up to a total travel distance of the ray $d(m)$. The sound source is assumed to send out the discrete unit impulse function (Kronecker delta function) $\delta(n)$, see Equation \ref{equ:delta}. As non-integer delays are ignored in this implementation, the shader will just write to the rounded integer delay location $\tau_s$ in the impulse response $H(n)$ that corresponds to the distance:
\begin{equation}
\label{equ:delta}
\delta [n]={\begin{cases}1,&n=0\\0,&n\neq 0\end{cases}}\,
\end{equation}

\begin{equation}
H(n) = \sum_{m=0}^M \delta(n-\tau_s(m))\cdot \alpha(m)\cdot (-1)^{K(m)}
\end{equation}
The total attenuation per ray $\alpha(m)$ can be computed by using a material-dependent coefficient of reflection $\alpha_{mat}$ that is stored in the \texttt{Sdf struct}. At each reflection pass $k$ this results in a possibly different reflection pass-dependent coefficient $\alpha_{mat}(k,m)$. $\alpha(m)$ can finally be computed by keeping a running product within the loop of Listing \ref{lst:mainloop}:
\begin{equation}
\alpha(m)=\prod_{k=0}^{K(m)} \alpha_{mat}(k,m)
\end{equation}
For simplicity's sake, only one global coefficient $\alpha_G$ is implemented here, resulting in:
\begin{equation}
\alpha(m) = \alpha_G^{K(m)}
\end{equation}

Additionally, a proof of concept for frequency-dependent loss for each reflection is introduced to the model. As a computationally efficient heuristic, a binomial filter is used \cite{aubury_binomial_1996}, \cite{derpanis_overview_nodate}. A simple one-zero filter $G(z)$ is applied for each reflection:

\begin{equation}
G(z,K) = (1+z^{-1})^K \cdot \left(\frac{1}{2}\right)^K
\end{equation}
The advantage of using such a simple filter is that a $K$-stage cascade's impulse response can be computed easily without applying the filter repeatedly. By doing the inverse discrete-time Fourier transform $\mathfrak{F}^{-1}$ of the transfer function $G(z)$ the $N$-length impulse response is obtained:

\begin{equation}
  g(n,K) = \mathfrak{F}^{-1}\{ G(z) \} = \left(\frac{1}{2}\right)^K \frac{1}{N}  \sum_{\omega = 0}^\pi (1+e^{-j\omega})^{K} e^{j\omega n} 
\end{equation}
A binomial filter's impulse response converges to a Gaussian bell curve \cite{aubury_binomial_1996}, which can be approximated as:

\begin{equation}
G(n,K) \approx  \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot e ^{-\frac{1}{2} (\frac{n-\mu}{\sigma})^2}
\label{eq:assump}
\end{equation}


with 

\begin{equation}
\sigma = \sqrt{K 0.231 + 0.562}
\end{equation}
and 
\begin{equation}
\mu = \frac{K}{2} + \frac{1}{2}
\end{equation}

The right-hand side of Equation \ref{eq:assump} is simply the normal distribution, which is computationally efficient to calculate for any $K$.

So instead of adding $\delta(n-\tau(m))$ into the RIR, $g(n-\tau(m),K)$ is simply used instead. 
Similar to many other implementations, a high-pass filter is applied to the resulting RIR to compensate for low-frequency components resulting mainly from the spatial extension of the sound receiver shape.

\subsubsection*{Other Frequency-Dependent Models}
Besides the faster binomial filter approach, a function for IIR filters was implemented in case a filter is needed whose $K^{th}$-order serial cascade impulse response is not known. Also, if different materials are set up in the scene and different filters need to be applied, the binomial filter strategy is not applicable, so this approach demonstrates a more realistic scenario. The filter(s) needs to be set up as sample-by-sample functions and iterated over an array. The result is inserted just as $g(n)$ above.

\subsubsection*{Output}
After the RIR is computed, it needs to be written to the shader's output texture. This way, an intermediate rectangular representation of $N \times M$ pixels is produced. The RIR, $h(n)$ is written to the Texture $T(x,y)$:
\begin{equation}
  T(x,y) = H(x \bmod N+\frac{y}{M})
\end{equation}

Depending on the use case (saving the RIR to a file, possible auralization or convolution on the GPU), this data then needs to be fetched from the GPU and the latter process needs to be reverted to obtain a one-dimensional signal again.


\begin{figure*}[ht]
    \center
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/specBrink}
      \caption{\label{fig:fig:multReflSpecOrig} \it Original recording, scene 1, multiple reflections from \cite{brinkmann_round_2019}. }
    \end{subfigure}% 
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/simBrink}
      \caption{\label{fig:multReflSpecSim} \it Simulated using the proposed method. }
    \end{subfigure}
    \caption{\it Comparison of spectra of a real impulse response (a) and the proposed method (b).}
    \label{fig:multReflSpecCompare}
\end{figure*}


\section{Results}

\begin{figure*}[ht]
    \center
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/shoebox_orig}
    \caption{\label{fig:shoeA} \it Computed using \cite{lehmann_fast_2020}. }
    \end{subfigure}% 
    \begin{subfigure}[t]{0.45\textwidth}
      \centering
      \input{img/shoebox_sim}
      \caption{\label{fig:shoeB} \it Simulated using the proposed method. }
    \end{subfigure}
    \caption{\it Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}.}
    \label{fig:showSpecs}
\end{figure*}


\begin{figure}

    \begin{center}
      \input{img/brink}
    \end{center}
    
    \caption{\label{fig:multRefl} \it RIR computed using the proposed method and measured by \cite{brinkmann_round_2019}, scene 3, multiple reflection at opposed MDF plates.}
\end{figure}

\begin{figure}
    \begin{center}
      \input{img/brinkDiff}
    \end{center}
    
    \caption{\label{fig:diffuser} \it RIR computed using the proposed method and measured by \cite{brinkmann_round_2019}, scene 1, a single reflection with a diffuser.}
\end{figure}



This paper presents results and comparisons in 3 different scenarios:
\begin{itemize}
\item A scene with two opposing medium-density fibreboard (MDF) plates, causing multiple echoes, "Scene 3, multiple reflections", taken from \cite{brinkmann_round_2019}
\item A scene with one reflection from a diffusor in an otherwise anechoic chamber, "Scene 1, diffusor", taken from \cite{brinkmann_round_2019}
\item A shoebox scene, simulated with this work and \cite{lehmann_fast_2020} for reference.
\end{itemize}
An example application is provided in the framework \texttt{TouchDesigner}. The application as well as all generated data and \texttt{Jupyter Notebooks} can be found on this project's github repository \footnote{ \href{https://github.com/hrtlacek/rayMarchReverb}{github.com/hrtlacek/rayMarchReverb}} \\
All of the following results have been computed using $1024^2$ rays with each ray undergoing 10 reflections. The computations were made on a strong consumer-grade machine (Intel i7 CPU, NVIDIA Geforce 1080ti). The computation time for simple scenes such as "scene 1, rigid" in \cite{brinkmann_round_2019} was less than $\frac{1}{60}$ seconds including the computation of a simple visualization in real time. The most complex scenes (geometrically and in regards to the amount of reflections) that were tested, the shoebox scene and "scene 1 diffusor", where computed in less than $\frac{1}{50}$ seconds. As expected, the method's inherent parallelism gives fast execution times and interpolation could be used to create audio-rate RIRs for real time usage. \

% The results are compared to a different simulation using the image source method \cite{lehmann_fast_2020} and \cite{brinkmann_round_2019} who generated a dataset featuring recordings in in an anechoic chamber with simple shapes. 
% \subsection*{Scene 1, diffusor}

Since this implementation lacks features such as material-specific reflection coefficients and passes for multiple octave bands (computing low and high frequency behavior separately), it is not possible to accurately compare previous work with the proposed method by simply using the same materials. Still Figures \ref{fig:diffuser} - \ref{fig:shoe} might give the reader an impression that the proposed method has deficits but is able to produce results rather similar to the reference RIRs considering the many simplifications. Generally it can be shown that by adjusting reflection coefficients, the method can be matched up to resemble existing work. \\
The results from "Scene 3, multiple reflections" can be observed in Figure \ref{fig:multRefl} in the time domain and a spectrogram is shown in Fig. \ref{fig:multReflSpecCompare}. Note that the comparison with \cite{brinkmann_round_2019} in Figure \ref{fig:multRefl} ignores the frequency response of the speaker and microphone that were used in the original recording. As can be seen in the plot, the original recording features a visible amount of difference to an ideal impulse even with the direct signal. Fig. \ref{fig:multReflSpecCompare} seems to indicate that the material dependent filtering seems too simple in the proposed method, unable to capture a similar falloff of high and low frequencies. The time domain plot in Figure \ref{fig:multRefl} seems to show that the echo times slightly differ from the reference which might be related to the growth of the receiver volume $V_r$.
Figure \ref{fig:diffuser} shows another plot to show this implementation's reaction to a more complex scene including a diffusor.  
Figure \ref{fig:showSpecs} shows the spectra of a simple shoebox room simulation in comparison to \cite{lehmann_fast_2020}. The time domain plot of this comparison can be found in Figure \ref{fig:shoe}. The shoebox scene features a small room with dimensions $3 \times 4 \times 2.5$ meters. Note that \cite{lehmann_fast_2020} used a sampling rate of 16kHz and has been up-sampled to 44.1 kHz for comparison reasons.

Given the proof-of-concept nature of this proposal, there is a lot of room for improvement in terms of accuracy. More audio examples than are shown here can be inspected at the project's github repository.



\begin{figure}
    \begin{center}
      \input{img/shoebox}
    \end{center}
    \caption{\label{fig:shoe} \it Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
\end{figure}

\section{Conclusions and future work}
\label{sec:concl}

This work was able to show that RIR estimation via SDFs in a compute shader in a real time-compatible manner is possible. It remains to be tested how far this method can reach. While it still is computationally costly to do these calculations in general, the use of SDFs can offer some significant advantages such as their procedural nature, their efficiency and simplicity. A number of improvements both in speed and accuracy are possible in the proposed technique, such as reduction of if-statements, material-dependent attenuation and scattering, for example. Also, a number of speed improvements and optimizations could be implemented such as the removal of if statements in the SDF function. Furthermore, a more detailed comparison and more mature and rigorous mathematical analysis of the process seems promising, as well as an analysis of the sphere tracing-specific artifacts and their effects in the audio domain. As mentioned in Section \ref{subs:mot}, sphere tracing seems to offer a surprising simplicity and elegance, for example when it comes to smoothing geometry. Simply the fact that it is a rather different approach than classical ray casting of polygons seems to promise opportunities for further research. 

An SDF's closeness to classical mathematical structures (in contrast to sets of triangles, vertices, edges, etc.) might lead to easier analysis or simpler comparison of different algorithms. Their popularity in the graphics community leads to constant development and the sheer amount of activity in the field seems to promise greater ease of use in the future. \
\begin{figure}[ht]
    \center
    \begin{subfigure}[t]{0.4\linewidth}
      \centering
      \includegraphics[width=1\linewidth]{img/julia.png}
    \caption{\label{fig:juliaRend} \it Visualization. }
    \end{subfigure} \

    \begin{subfigure}[t]{0.4\linewidth}
      \centering
      \input{img/julia.tex}
      \caption{\label{fig:juliaRIR} \it RIR simulated using the proposed method. }
    \end{subfigure}
    \caption{\it Visualization (a) and RIR (b) of a 3-dimensional projection of a 4-dimensional function, the Julia Set \cite{quilez_inigo_nodate-1} .}
    \label{fig:julia}
\end{figure}

Certain rather experimental ideas are easy to realize in this technique as well. Due to the aforementioned connection between geometry formulation in sphere tracing and mathematical formulas, this algorithm is often used to render fractals. In this context, this would mean that it is rather easy to calculate the RIR of a Menger sponge or a Julia Set (see Figure \ref{fig:julia} for a visualization and RIR). Moreover, many geometries/SDFs can be formulated in a dimension-independent way, resulting in a straightforward way to render 4-dimensional geometries, leading to the idea of calculating the RIR of a 4-dimensional room. While these thoughts do not offer any apparent practical application and might "only" lead to aesthetically interesting results, it is possible to find applications in the sonification of high dimensional data.



% Please, submit full-length papers (max.~8 pages both oral and poster presentations).
% Submission is fully electronic and automated through the Conference Web Submission System.
% DO NOT send us papers directly by e-mail.

% \section{Acknowledgments}
% This work was supported in part by the university of Applied sciences St.Poelten.
% Thanks to inigo quilez, the shadertoy community.
% Many thanks to the great number of anonymous reviewers!

%\newpage
\nocite{*}
\bibliographystyle{IEEEbib}
\bibliography{RaymarchReverb2}


\end{document}





% \begin{figure}
%     \begin{center}
%       \input{img/normDist}
%         % \input{img/mytikz.tex}
%     \end{center}
%     \caption{A PGF histogram from \texttt{matplotlib}.}
% \end{figure}


% Advantage of compute shader.
% Maybe introduce cascaded Lowpass.



% All figures should be centred on the column (or page, if the figure spans both columns).
% Figure captions (in italic) should follow each figure and have the format given in Figure \ref{fft_plot}.
% %
% Vectorial figures are preferred. For example when using
% \texttt{Matlab}, export using either Postscript or PDF format. Also,
% in order to provide a better readability, figure text font size
% should be at least identical to footnote font size. To do so using
% \texttt{Matlab}, use the \texttt{subplot} command before plotting.
% If bitmap figures are used, please make sure that the resolution is
% enough for print quality. Fig. \ref{ftt_plot2} illustrates an
% example of a figure spanning two columns.
%


% \begin{figure}
%     \begin{center}
%       \input{img/spec1}
%     \end{center}
%     \caption{\label{fig:shoe} \it Spec by this approach. Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
% \end{figure}



% \begin{figure}
%     \begin{center}
%       \input{img/orig}
%     \end{center}
%     \caption{\label{fig:shoe} \it Spec by matlab. Impulse response of shoebox room. Computed using the proposed method and \cite{lehmann_fast_2020}. }
    
% \end{figure}


% \begin{figure}
%     \begin{center}
%       \input{img/specBrink}
%     \end{center}
%     \caption{\label{fig:shoe} \it Original \cite{brinkmann_round_2019}. }
    
% \end{figure}


% \begin{figure}
%     \begin{center}
%       \input{img/simBrink}
%     \end{center}
%     \caption{\label{fig:shoe} \it Simulated. }
    
% \end{figure}

% \begin{enumerate}



% Eric A. Lehmann (2020). Fast simulation of acoustic room impulse responses (image-source method) (https://www.mathworks.com/matlabcentral/fileexchange/25965-fast-simulation-of-acoustic-room-impulse-responses-image-source-method), MATLAB Central File Exchange. Retrieved February 14, 2020.

% \end{enumerate}


% \begin{figure}[ht]
% \centerline{\includegraphics[scale=0.8]{fft_plot2}}
% \caption{\label{fft_plot}{\it Sinusoid in time and frequency domain. Short captions are centred, long captions (more than 1 line) are justified.}}
% \end{figure}
% %
% \begin{figure*}[ht]
% \center
% \includegraphics[width=5in]{TwoColumnSine2}
% \caption{\label{ftt_plot2}{\it A figure spanning two columns, as mentioned in Sec. . }}
% \end{figure*}


% \begin{figure}[ht]
% \centerline{\includegraphics[scale=0.8]{img/test1.pgf}}
% \caption{\label{fft_plot}{\it Sinusoid in time and frequency domain. Short captions are centred, long captions (more than 1 line) are justified.}}
% \end{figure}

% \begin{figure}
%     \begin{center}
%       \input{img/ir_sc3_rigid_0}
%         % \input{img/mytikz.tex}
%     \end{center}
%     \caption{A PGF histogram from \texttt{matplotlib}.}
% \end{figure}




% \subsection{Tables}
% As for figures, all tables should be centered on the column (or page, if the table spans both columns).
% Table captions should be in italic, precede each table and have the format given in Table \ref{tab:example}.

% \begin{table}[ht]
%   \caption{\itshape Basic trigonometric values.}
%   \centering
%   \begin{tabular}{|c|c|}
%     \hline
%     $\mathrm{angle}\,(\theta, \mathrm{rad})$ & $\sin \theta$ \\\hline
%     $\frac{\pi}{2}$ & $1$ \\
%     $\pi$ & $0$ \\
%     $\frac{3\pi}{2}$ & $-1$ \\
%     $2\pi$ & $0$ \\\hline
%   \end{tabular}
%   %
%   \label{tab:example}
% \end{table}

% \begin{table*}[ht]
%   \caption{{\it Basic trigonometric values, spanning two columns.}}
%   \centering
%   \begin{tabular}{|c|c|c|c|c|c|c|}\hline
%     $\mathrm{angle}\, (\theta, \mathrm{rad})$ & $\sin \theta$ & $\cos \theta $ & $(\sin \theta)/2 $ & $(\cos \theta) /2 $ & $(\sin \theta)/3 $ & $(\cos \theta)/3$    \\\hline
%     $\frac{\pi}{2}$ & $1$ & $0$ & $1/2$ & $0$ & $1/3$ & $0$ \\
%     $\pi$ & $0$ & $-1$ & $0$ & $-1/2$ & $0$ & $-1/3$\\
%     $\frac{3\pi}{2}$ & $-1$ & $0$ & $-1/2$ & $0$ & $-1/3$ & $0$ \\
%     $2\pi$ & $0$ & $1$ & $0$ & $1/2$ & $0$ & $1/3$ \\\hline
%  \end{tabular}
%   %
%   \label{tab:example2}
% \end{table*}

% \subsection{Equations}
% Equations should be placed on separate lines and numbered:

% \begin{equation}
%   X(e^{j\Omega})=\sum_{n=0}^{N-1}x(n)e^{-j\Omega n}
%   \label{eq1}
%   \end{equation}
%   where the sequence $x(n)$ in equation (\ref{eq1}) is a windowed frame:
%   \begin{equation}
%   x(n)=s(n) w(n)
%   \label{eq2}
% \end{equation}
% %
% with a window function $w(n)$.
